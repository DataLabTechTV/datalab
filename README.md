# Data Lab

Tooling for a minimalist data lab running on top of DuckLake.


## Components

### ingest/

### transform/

### local/

### logs/

### dlctl


## Ingestion

As a rule of thumb, ingestion will be done via the `dlctl ingest` command. If a version for the current date already exists, it will output an error and do nothingâ€”just wait a second.

### Manual

For manually uploaded datasets, you can create a directory in S3 by giving it the dataset name:

```bash
dlctl ingest --standalone --dataset "Your Dataset Name"
```

This will create a directory `s3://lakehouse/raw/your_dataset_name/2025-06-03/19-56-03` and print the path to stdout.

### Kaggle

### Hugging Face

### Other

### ğŸ—ƒï¸ Storage Layout

All data is stored in a single S3 bucket (e.g., `s3://lakehouse`, tested with MinIO), with directory structure:

```
s3://lakehouse/
â”œâ”€â”€ catalog/
â”‚   â””â”€â”€ backups/
â”œâ”€â”€ raw/
â”‚   â””â”€â”€ <dataset-name>/
â”‚       â””â”€â”€ YYYY-MM-DD/
â”‚           â””â”€â”€ HH-mm-SS/
â”‚               â”œâ”€â”€ *.csv
â”‚               â”œâ”€â”€ *.json
â”‚               â””â”€â”€ *.parquet
â”œâ”€â”€ stage/
â”‚   â””â”€â”€ <dataset-name>/
â”‚           â””â”€â”€ *.parquet
â”œâ”€â”€ marts/
â”‚   â””â”€â”€ <domain>/
â”‚           â””â”€â”€ *.parquet
â””â”€â”€ logs/
```

## Transformation

Transformations can be run via `dlctl transform`, which will run:

```bash
cd transform/ && dbt run
```
