services:
  minio:
    profiles:
      - dev
    image: minio/minio:RELEASE.2025-09-07T16-13-09Z
    ports:
      - "9000:9000"
      - "9001:9001"
    environment:
      - MINIO_ROOT_USER=${S3_ACCESS_KEY_ID}
      - MINIO_ROOT_PASSWORD=${S3_SECRET_ACCESS_KEY}
    volumes:
      - minio:/data
    networks:
      - minio
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 10s
      retries: 5
    restart: unless-stopped
    command: server /data --console-address ":9001"

  minio-init:
    profiles:
      - dev
    image: minio/mc:RELEASE.2025-08-13T08-35-41Z
    networks:
      - minio
    depends_on:
      minio:
        condition: service_healthy
    entrypoint: >
      /bin/sh -c "
      /usr/bin/mc alias set minio http://minio:9000 $S3_ACCESS_KEY_ID $S3_SECRET_ACCESS_KEY;
      /usr/bin/mc mb --ignore-existing minio/${S3_BUCKET};
      "
    restart: no

  ollama:
    image: ollama/ollama:0.12.3
    ports:
      - "11434:11434"
    volumes:
      - ollama:/root/.ollama
    networks:
      - ollama
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "ollama", "ls"]
      interval: 10s
      retries: 3
    restart: unless-stopped

  ollama-init:
    image: alpine/curl:8.14.1
    networks:
      - ollama
    depends_on:
      ollama:
        condition: service_healthy
    environment:
      MODELS: ${OLLAMA_MODELS}
    entrypoint: |
      /bin/sh -c '
      IFS=,; set -- $${MODELS};
      for model in "$$@"; do
        echo "==> Downloading model: $$model"
        curl -X POST http://ollama:11434/api/pull \
          -H "Content-Type: application/json" \
          -d "{\"name\": \"$$model\"}"
      done
      '
    restart: no

  mlflow:
    build:
      context: ./mlflow
      dockerfile: Dockerfile
    ports:
      - "5000:5000"
    volumes:
      - mlflow:/mlflow
    networks:
      - mlflow
    environment:
      MLFLOW_S3_ENDPOINT_URL: http://${S3_ENDPOINT}
      AWS_ACCESS_KEY_ID: ${S3_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${S3_SECRET_ACCESS_KEY}
      AWS_DEFAULT_REGION: ${S3_REGION}
      AWS_S3_ADDRESSING_STYLE: ${S3_URL_STYLE}
    command: >
      mlflow server
        --backend-store-uri sqlite:///mlflow/mlflow.db
        --serve-artifacts
        --artifacts-destination s3://${S3_MLFLOW_BUCKET}/${S3_MLFLOW_ARTIFACTS_PREFIX}
        --host 0.0.0.0
        --port 5000
    healthcheck:
      test: >
        python -c "import urllib.request;
        urllib.request.urlopen('http://localhost:5000')"
      interval: 10s
      retries: 5
    restart: unless-stopped

  kafka:
    image: apache/kafka:4.0.0
    ports:
      - "9092:9092"
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller

      KAFKA_LISTENERS: EXTERNAL://:9092,INTERNAL://:29092,CONTROLLER://:9093
      KAFKA_ADVERTISED_LISTENERS: EXTERNAL://localhost:9092,INTERNAL://kafka:29092

      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,EXTERNAL:PLAINTEXT,INTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL

      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka:9093

      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0

      KAFKA_LOG_DIRS: /var/lib/kafka/data
    volumes:
      - kafka:/var/lib/kafka/data
    networks:
      - kafka
    healthcheck:
      test: [
        "CMD", "bash", "-c",
        "/opt/kafka/bin/kafka-topics.sh --bootstrap-server kafka:29092 --list"
      ]
      interval: 10s
      retries: 5
    restart: unless-stopped

  kafka-init:
    image: apache/kafka:4.0.0
    environment:
      KAFKA_GROUP_TOPIC_LIST: ${KAFKA_GROUP_TOPIC_LIST}
    networks:
      - kafka
    depends_on:
      kafka:
        condition: service_healthy
    command: |
        /bin/bash -c '
        for topic_group in $${KAFKA_GROUP_TOPIC_LIST//,/ }; do
          IFS=':' read -r topic group <<< "$$topic_group"

          echo "Creating topic: $$topic"
          /opt/kafka/bin/kafka-topics.sh \
            --bootstrap-server kafka:29092 \
            --create --if-not-exists --topic $$topic \
            --partitions 1 --replication-factor 1

          echo "Initializing consumer for topic $$topic and group $$group"
          /opt/kafka/bin/kafka-console-consumer.sh \
            --bootstrap-server kafka:29092 \
            --topic $$topic \
            --group $$group \
            --timeout-ms 5000
        done
        '
    restart: no

  portainer:
    image: portainer/portainer-ce:2.33.2
    ports:
      - 9443:9443
    volumes:
      - portainer:/data
    networks:
      - portainer

volumes:
  minio:
  ollama:
  mlflow:
  kafka:
  portainer:

networks:
  ollama:
  minio:
  mlflow:
  kafka:
  portainer:
